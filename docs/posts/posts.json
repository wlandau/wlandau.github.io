[
  {
    "path": "posts/2023-10-04-pace/",
    "title": "A strategic change of pace for public-facing communication",
    "description": "Why my messages have slowed down.",
    "author": [
      {
        "name": "Will Landau",
        "url": {}
      }
    ],
    "date": "2023-10-04",
    "categories": [
      "communication",
      "community",
      "productivity"
    ],
    "contents": "\nBackground\nI love to create and maintain open-source software. It is a joy to write code to solve problems, release solutions for everyone, and keep packages working so problems stay solved. I want to keep developing and engineering for as long as possible.\nProblem\nAlthough I value and grow from user feedback, I now face an overwhelming volume of questions and requests about the projects I maintain. Requests come at all times of day on all days of the week, and each response is a context switch. The high throughput of constant communication wears me down.\nSolution\nLate last month, I created digital boundaries to protect my mental health and productivity. My GitHub notifications, social media, and package maintainer identity now use a special email account that I only check on certain days of the week. The benefits were immediate, and the changes are here to stay.\nWhat this means for users\nI send most of my messages during the middle part of the week, usually Wednesdays. I may be slower to communicate than in previous years, but I am still committed to helping users. And I am not slowing down at all when it comes to actual software engineering. Far from it: these communication boundaries are giving me more time and energy to fix bugs, add new features, and create new packages.\nHow you can help\nIf you use targets, crew, or any of my other packages, I would be grateful for help answering GitHub issues and discussions, especially at https://github.com/ropensci/targets/discussions. And if you are posting a request yourself, please respect the communication and reproducibility guidelines that I describe at https://books.ropensci.org/targets/help.html.\n\n\n\n",
    "preview": "posts/2023-10-04-pace/image.jpg",
    "last_modified": "2023-12-14T14:50:41-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-18-non-blocking-app/",
    "title": "Non-blocking Shiny apps",
    "description": "A convenient way to launch a Shiny app without blocking your R session.",
    "author": [
      {
        "name": "Will Landau",
        "url": {}
      }
    ],
    "date": "2020-12-18",
    "categories": [
      "rstats",
      "shiny"
    ],
    "contents": "\nAn example\nThe targets package has a new Shiny app to monitor progress.1 To try it out, set up a new pipeline.\n\n\n# Write in _targets.R:\nlibrary(targets)\nsleep_run <- function(...) Sys.sleep(10)\nlist(\n  tar_target(data1, sleep_run()),\n  tar_target(data2, sleep_run()),\n  tar_target(model1, sleep_run(data1)),\n  tar_target(model2, sleep_run(data2)),\n  tar_target(conclusions, sleep_run(c(model1, model2)))\n)\n\n\n\nThen launch the app in your R console.\n\n\nlibrary(targets)\ntar_watch(targets_only = TRUE, outdated = FALSE, seconds = 10)\n#> ● url: http://127.0.0.1:57726\n#> ● host: 127.0.0.1\n#> ● port: 57726\n\n\n\nA new browser window should show a visNetwork graph that reloads every 10 seconds.\n\nThe app does not block your R session, so your R console is free to run the pipeline.\n\n\ntar_make()\n#> ● run target data1\n#> ● run target data2\n#> ● run target model1\n\n\n\nAs the pipeline progresses, the visNetwork graph should periodically refresh and show you the latest status of each target.\n\nThe challenge\nShiny functions shinyApp() and runApp() both block the R console. While they are running, your R session cannot do anything else.\n\n> runApp()\n\nListening on http://127.0.0.1:5160\n\nSo how is it possible to run tar_watch() and tar_make() at the same time?\nA convenient solution\nFirst, write a function that actually runs the app at a given IP address2 and TCP port.3 The options argument of shinyApp() is key.\n\n\nrun_app <- function(host = \"127.0.0.1\", port = 49152) {\n  ui <- bs4Dash::bs4DashPage(...) # bs4Dash creates nice-looking Shiny UIs.\n  server <- function(input, output, session) {...}\n  shiny::shinyApp(ui, server, options = list(host = host, port = port))\n}\n\n\n\nNext, launch the app in a callr::r_bg() background process.\n\n\nargs <- list(host = \"127.0.0.1\", port = 49152)\nprocess <- callr::r_bg(func = run_app, args = args, supervise = TRUE)\n\n\n\nAt this point, the app may take an unpredictable length of time to initialize. With pingr, we can wait until the app comes online.4 We also check if the background process quit early and forward any errors to the parent process.5\n\n\nwhile(!pingr::is_up(destination = \"127.0.0.1\", port = 49152)) {\n  if (!process$is_alive()) stop(process$read_all_error())\n  Sys.sleep(0.01)\n}\n\n\n\nAfter the loop completes, open the app in a web browser.\n\n\nbrowseURL(\"http://127.0.0.1:49152\")\n\n\n\nNow, you can use the app and the R console at the same time.\n\n> # Ready for input.\n\n\nThe full source code of the tar_watch() app is available in the targets package. To embed this feature in your own app as a Shiny module, see functions tar_watch_ui() and tar_watch_server()↩︎\nMost users can use localhost (host = \"127.0.0.1\"). If your web browser is running on a different computer than the one running the app, use host = \"0.0.0.0\" and ensure the two computers share the same local network.↩︎\nFor a personal app like this, I recommend choosing a port in the dynamic range between 49152 and 65535 so it does not conflict with critical infrastructure on your computer.↩︎\nThis loop may take few seconds, so a cli spinner is a nice touch.↩︎\nThanks Kirill Müller for thinking of this.↩︎\n",
    "preview": "posts/2020-12-18-non-blocking-app/app-run.png",
    "last_modified": "2023-12-14T14:50:41-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-14-targetopia/",
    "title": "The R Targetopia",
    "description": "A new R package ecosystem for democratized reproducible pipelines at scale",
    "author": [
      {
        "name": "Will Landau",
        "url": {}
      }
    ],
    "date": "2020-12-14",
    "categories": [
      "rstats",
      "targetopia"
    ],
    "contents": "\n\n\n\nThe targets R package is a Make-like pipeline toolkit for reproducible data science. It tackles copious workflows and demanding runtimes to accelerate research papers, simulation studies, and other computationally intense projects in fields such as Bayesian statistics and machine learning. Relative to its predecessor, drake, targets is not only more efficient, but also more extensible. The modular interface and object-oriented design allow package developers to write reusable target factories.1 If you want to help other data scientists create a certain specialized kind of pipeline, you can write a function that creates a list of target objects.\n\n\n# yourExamplePackage/R/example_target_factory.R\ntarget_factory <- function(data) {\n  list(\n    tar_target_raw(\"file\", data, format = \"file\"),\n    tar_target_raw(\"simple_model\", quote(run_simple(file))),\n    tar_target_raw(\"flexible_model\", quote(run_flexible(file))),\n    tar_target_raw(\"conclusions\", quote(summarize(simple_model, flexible_model)))\n  )\n}\n\n\n\nThen, when users of your package write _targets.R, the pipeline becomes much easier to express.\n\n\n# _targets.R\nlibrary(targets)\nlibrary(yourExamplePackage)\ntarget_factory(\"dataset.csv\") # End with a list of targets.\n\n\n\n\n\n\n\n\ntar_visnetwork(targets_only = TRUE)\n\n\n\n\nWith pre-packaged target factories, end users do not need to write as much code, and they do not need to be familiar with the advanced features of targets.\n\n\n\nThe R Targetopia is the Pandora’s Box of low-hanging fruit that dangles from target factories, and its goal is to democratize reproducible pipelines across more of the R community. It is a growing ecosystem of R packages that abstract away the most difficult parts of targets and make workflows simple and quick to write.\nAt the time of writing, the newest R Targetopia package is stantargets, a domain-specific workflow framework for Bayesian data analysis with Stan. With stantargets, writing a complex simulation study is as simple as a one call to tar_stan_mcmc_rep_summary(). This complicated pipeline condenses down to the simple one below. Not only is the code shorter, but advanced concepts like file tracking, dynamic branching, and batching are completely abstracted far away from the user. Bayesian statisticians can spend less time on software development and more time on model development.\n\n\n# _targets.R\nlibrary(targets)\nlibrary(stantargets)\nstan_targets <- tar_stan_mcmc_rep_summary(\n  model,\n  \"model.stan\",\n  generate_stan_data(), # custom function\n  batches = 40, # Batching reduces overhead.\n  reps = 25, # reps per batch\n  variables = c(\"beta\", \"true_beta_value\"),\n  summaries = list(\n    ~posterior::quantile2(.x, probs = c(0.025, 0.5, 0.975))\n  )\n)\nstan_targets\n\n\n\ntarchetypes is a more general R Targetopia package that simplifies general-purpose tasks such as static branching and parameterized R Markdown. As described here, it is straightforward to reproducibly render a parameterized R Markdown report repeatedly across a large grid of parameters.\n\n\n# _targets.R\nlibrary(targets)\nlibrary(tarchetypes)\nlibrary(tibble)\nlist(\n  tar_target(x, \"value_of_x\"),\n  tar_render_rep(\n    report,\n    \"report.Rmd\",\n    params = generate_large_param_grid(), # custom function\n    batches = 50 # Batching reduces overhead.\n  )\n)\n\n\n\n\n\n\n2\nIf you like developing R packages, please consider contributing an R Targetopia package for your own field of data science. I do plan to post detailed guidance in early 2021. But for now, the main piece is a target factory that calls tar_target_raw(). Functions substitute(), tar_sub(), and tar_eval() can help create language objects for the command argument of tar_target_raw(). Functions tar_manifest(), tar_network(), tar_dir(), and tar_test() help write examples and tests. Feel free to borrow the source code of tarchetypes or stantargets, and do not hesitate to reach out.\n@wlandau\n@wmlandau\n@wlandau\n\n\n\n\nIn early 2020, my colleague Richard Payne wrote a package to support a specialized drake plan factory, an idea that I previously underestimated. His package helped users create pipelines of their own, but it struggled against the constraints of drake_plan(), which is a major reason I decided to design targets with target factories in mind.↩︎\nFigure from https://openclipart.org/image/2000px/188840.↩︎\n",
    "preview": "posts/2020-12-14-targetopia/preview2.png",
    "last_modified": "2023-12-14T14:50:41-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-13-distill/",
    "title": "RStudio distill",
    "description": "A fresh start using RStudio's latest web format",
    "author": [
      {
        "name": "Will Landau",
        "url": {}
      }
    ],
    "date": "2020-12-13",
    "categories": [
      "rstats",
      "rstudio"
    ],
    "contents": "\n\n\n\nRstudio just announced the CRAN release of distill, an R package for formatting scientific and technical websites.1 Like all RStudio tools, distill is super easy to use. It took only a few minutes to convert my old portfolio into a nicer-looking personal website.\nThe release of distill is timely. After a challenging 2020, it is nice to have a little nudge to refresh and regroup for 2021.\nFor me personally, this is the right time to rebuild my website. It has been four years since I started my career, and I now have a better understanding of how I fit into my professional community.\n\nHex logo from https://github.com/rstudio/distill. Copyright RStudio, PBC.↩︎\n",
    "preview": "posts/2020-12-13-distill/preview.png",
    "last_modified": "2023-12-14T14:50:41-05:00",
    "input_file": {}
  }
]
